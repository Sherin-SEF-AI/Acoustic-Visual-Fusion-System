"""
Main Window for the Acoustic-Visual Fusion System - Advanced Implementation.
"""

import sys
import time
import threading
from typing import Optional
import numpy as np

from PyQt6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QLabel, QFrame, QSplitter, QStatusBar, QMessageBox, QTabWidget,
    QToolBar, QMenuBar, QMenu, QDockWidget
)
from PyQt6.QtCore import Qt, QTimer, pyqtSignal, QObject, QThread, QSize
from PyQt6.QtGui import QFont, QAction, QIcon, QKeySequence
from loguru import logger

from .theme import DARK_THEME
from .camera_panel import CameraPanel
from .audio_panel import AudioPanel
from .fusion_panel import FusionPanel
from .controls_panel import ControlsPanel
from .timeline_widget import EventTimelinePanel, EventType
from .scene_3d_widget import Scene3DPanel
from .analytics_panel import AnalyticsPanel
from .recording_widget import RecordingWidget
from .settings_dialog import SettingsDialog
from .heatmap_widget import HeatmapPanel
from .alert_panel import AlertPanel, AlertSeverity
from .shortcuts import ShortcutManager
from .notifications import NotificationManager
from .meeting_panel import MeetingPanel
from .relationship_graph import RelationshipPanel


class ProcessingWorker(QThread):
    """Background worker for processing pipelines."""
    
    # Signals
    frame_ready = pyqtSignal(str, object, float)  # camera_id, frame, fps
    detections_ready = pyqtSignal(str, list)  # camera_id, detections
    tracks_ready = pyqtSignal(list)  # all tracks
    audio_ready = pyqtSignal(object)  # audio samples
    localization_ready = pyqtSignal(object, float)  # position, confidence
    mic_levels_ready = pyqtSignal(dict)  # mic_id -> (level, db)
    fusion_ready = pyqtSignal(list, list, list)  # sources, tracks, correlations
    stats_ready = pyqtSignal(float, float, float, float)  # fps, latency, cpu, gpu
    devices_ready = pyqtSignal(list, list)  # cameras, microphones
    event_detected = pyqtSignal(str, str, float)  # event_type, label, confidence
    meeting_data_ready = pyqtSignal(dict)  # meeting analytics data
    speech_detected = pyqtSignal(str, bool, float)  # track_id, is_speaking, confidence
    error_signal = pyqtSignal(str)
    
    def __init__(self, config, parent=None):
        super().__init__(parent)
        self.config = config
        self._running = False
        self._stop_requested = False
        
        # Components
        self.hardware_manager = None
        self.detector = None
        self.tracker = None
        self.localizer = None
        self.fusion = None
        
        # Analytics components
        self.meeting_analytics = None
        self.speech_detector = None
        
        # State
        self.frame_count = 0
        self.start_time = 0
        self.last_audio_time = 0
        self.last_analytics_time = 0
        self.detection_counts = {}
    
    def run(self):
        """Main processing loop."""
        self._running = True
        self._stop_requested = False
        self.start_time = time.time()
        
        try:
            self._initialize_components()
            self._processing_loop()
        except Exception as e:
            logger.error(f"Worker error: {e}")
            import traceback
            traceback.print_exc()
            self.error_signal.emit(str(e))
        finally:
            self._cleanup()
            self._running = False
    
    def _initialize_components(self):
        """Initialize all processing components."""
        from ..core.hardware_manager import HardwareManager
        from ..video.detection import ObjectDetector
        from ..video.tracking import MultiObjectTracker
        from ..audio.localization import SoundLocalizer
        from ..fusion.audio_visual_fusion import AudioVisualFusion
        
        logger.info("Initializing processing components...")
        
        # Hardware
        self.hardware_manager = HardwareManager(self.config)
        self.hardware_manager.initialize_all()
        
        # Emit discovered devices for GUI setup
        cameras = [{'id': c.id, 'name': c.name} 
                   for c in self.hardware_manager.cameras.values()]
        mics = [{'id': m.id, 'name': m.name} 
                for m in self.hardware_manager.microphones.values()]
        self.devices_ready.emit(cameras, mics)
        
        # Video components
        self.detector = ObjectDetector(
            model_name=self.config.video.detection.model,
            confidence_threshold=self.config.video.detection.confidence_threshold,
            classes=[0]  # Person only
        )
        self.tracker = MultiObjectTracker(
            track_buffer=self.config.video.tracking.track_buffer
        )
        
        # Audio components
        active_mics = self.hardware_manager.get_active_microphones()
        if active_mics:
            mic_positions = self.hardware_manager.get_microphone_positions()
            if mic_positions.shape[0] == 0 or np.allclose(mic_positions, 0):
                n = len(active_mics)
                mic_positions = np.zeros((n, 3))
                for i in range(n):
                    angle = 2 * np.pi * i / n
                    mic_positions[i] = [0.5 * np.cos(angle), 0.5 * np.sin(angle), 0]
                logger.info(f"Using default mic array positions for {n} mics")
            
            self.localizer = SoundLocalizer(
                microphone_positions=mic_positions,
                sample_rate=self.config.audio.capture.sample_rate
            )
        
        # Fusion
        self.fusion = AudioVisualFusion(
            max_distance=self.config.fusion.spatial.max_distance_m,
            temporal_window=self.config.fusion.temporal.window_ms / 1000
        )
        
        # Meeting Analytics
        try:
            from src.analytics.meeting_analytics import MeetingAnalytics
            from src.audio.speech_detection import SpeechDetector
            
            self.meeting_analytics = MeetingAnalytics()
            self.meeting_analytics.start_meeting()
            
            self.speech_detector = SpeechDetector(sample_rate=48000)
            logger.info("Meeting analytics initialized")
        except ImportError as e:
            logger.warning(f"Meeting analytics not available: {e}")
        
        logger.info("All components initialized")
    
    def _processing_loop(self):
        """Main processing loop."""
        frame_interval = 1.0 / 30
        
        while not self._stop_requested:
            loop_start = time.time()
            
            try:
                self._process_video_frame()
                self._process_audio()
                self._process_analytics()
                self._update_stats()
            except Exception as e:
                logger.error(f"Processing error: {e}")
            
            elapsed = time.time() - loop_start
            if elapsed < frame_interval:
                time.sleep(frame_interval - elapsed)
    
    def _process_video_frame(self):
        """Process video frames from all cameras."""
        if not self.hardware_manager:
            return
        
        all_detections = []
        
        for cam_id, camera in self.hardware_manager.cameras.items():
            frame = self.hardware_manager.read_camera(cam_id)
            
            if frame is not None:
                self.frame_count += 1
                elapsed = time.time() - self.start_time
                fps = self.frame_count / max(elapsed, 1)
                
                self.frame_ready.emit(cam_id, frame.copy(), fps)
                
                # Detection
                if self.detector:
                    detections = self.detector.detect(frame, cam_id, time.time())
                    
                    det_data = [
                        {'bbox': d.bbox.tolist(), 'conf': d.confidence, 
                         'class': d.class_name, 'camera': cam_id}
                        for d in detections
                    ]
                    self.detections_ready.emit(cam_id, det_data)
                    all_detections.extend(detections)
                    
                    # Track detection counts
                    for d in detections:
                        self.detection_counts[d.class_name] = \
                            self.detection_counts.get(d.class_name, 0) + 1
                    
                    # Emit events
                    if detections:
                        self.event_detected.emit(
                            "person", f"Person detected", detections[0].confidence
                        )
        
        # Tracking
        if self.tracker and all_detections:
            tracks = self.tracker.update(all_detections)
            track_data = [
                {'id': t.track_id, 'bbox': t.bbox.tolist(),
                 'class': t.class_name, 'camera': t.camera_id,
                 'is_speaking': False}
                for t in tracks
            ]
            self.tracks_ready.emit(track_data)
    
    def _process_audio(self):
        """Process real audio from microphones for localization."""
        current_time = time.time()
        if current_time - self.last_audio_time < 0.05:  # 20Hz update rate
            return
        self.last_audio_time = current_time
        
        if not self.hardware_manager:
            return
        
        # Try to get real audio from sounddevice
        try:
            import sounddevice as sd
            
            # Get real mic levels from active devices
            mic_levels = {}
            audio_data = []
            
            for mic_id, mic in self.hardware_manager.microphones.items():
                try:
                    # Record a short chunk from each mic
                    device_idx = mic.get('index')
                    if device_idx is not None:
                        # Non-blocking read of current input level
                        with sd.InputStream(device=device_idx, channels=1, 
                                           samplerate=48000, blocksize=1024) as stream:
                            data, overflowed = stream.read(1024)
                            
                            # Calculate RMS level
                            rms = np.sqrt(np.mean(data ** 2))
                            db = 20 * np.log10(max(rms, 1e-10))
                            mic_levels[mic_id] = (float(rms), float(db))
                            audio_data.append(data.flatten())
                except Exception as e:
                    # Fallback to estimated level
                    level = 0.01
                    db = -40.0
                    mic_levels[mic_id] = (level, db)
            
            self.mic_levels_ready.emit(mic_levels)
            
            # Emit combined audio waveform
            if audio_data:
                combined = np.mean(audio_data, axis=0) if len(audio_data) > 1 else audio_data[0]
                self.audio_ready.emit(combined)
                
                # Run localization if we have multi-channel data
                if self.localizer and len(audio_data) >= 2:
                    try:
                        multi_channel = np.column_stack(audio_data[:8])  # Max 8 channels
                        result = self.localizer.localize(multi_channel, current_time)
                        if result and result.confidence > 0.3:
                            self.localization_ready.emit(result.position, result.confidence)
                            self.event_detected.emit("sound", "Sound localized", result.confidence)
                    except Exception as e:
                        pass
                        
        except ImportError:
            # sounddevice not available - use hardware manager's method
            mic_levels = {}
            for mic_id in self.hardware_manager.microphones:
                # Try to get actual levels from ALSA
                level, db = self._get_alsa_mic_level(mic_id)
                mic_levels[mic_id] = (level, db)
            
            self.mic_levels_ready.emit(mic_levels)
            
            # Generate placeholder waveform based on real levels
            avg_level = np.mean([l for l, _ in mic_levels.values()]) if mic_levels else 0.01
            samples = np.random.randn(1024) * avg_level
            self.audio_ready.emit(samples)
    
    def _get_alsa_mic_level(self, mic_id: str) -> tuple:
        """Get microphone level from ALSA (Linux)."""
        try:
            import subprocess
            # Try to get ALSA recording level
            result = subprocess.run(
                ['amixer', '-c', '0', 'get', 'Capture'],
                capture_output=True, text=True, timeout=0.1
            )
            # Parse output for level percentage
            import re
            match = re.search(r'\[(\d+)%\]', result.stdout)
            if match:
                level = int(match.group(1)) / 100.0
                db = 20 * np.log10(max(level, 1e-10))
                return level, db
        except:
            pass
        return 0.05, -26.0
    
    def _process_analytics(self):
        """Process meeting analytics with real detection data."""
        current_time = time.time()
        
        # Update at 2Hz
        if current_time - self.last_analytics_time < 0.5:
            return
        self.last_analytics_time = current_time
        
        if not self.meeting_analytics:
            return
        
        try:
            # Get tracked persons from tracker
            if self.tracker and hasattr(self, '_last_tracks'):
                for track in self._last_tracks:
                    track_id = track.get('id', 'unknown')
                    
                    # Register as participant
                    self.meeting_analytics.register_participant(
                        str(track_id), 
                        f"Person {track_id}"
                    )
                    
                    # Detect if speaking based on audio correlation
                    is_speaking = track.get('is_speaking', False)
                    
                    # Update speech status
                    self.meeting_analytics.update_speech(
                        str(track_id), 
                        is_speaking,
                        current_time
                    )
            
            # Emit meeting data
            meeting_data = self.meeting_analytics.get_realtime_data()
            self.meeting_data_ready.emit(meeting_data)
            
        except Exception as e:
            logger.debug(f"Analytics error: {e}")
    
    def _update_stats(self):
        """Update performance statistics."""
        elapsed = time.time() - self.start_time
        fps = self.frame_count / max(elapsed, 1)
        latency = 33.0
        
        try:
            import psutil
            cpu = psutil.cpu_percent()
        except:
            cpu = 30.0
        
        gpu = 50.0
        self.stats_ready.emit(fps, latency, cpu, gpu)
    
    def _cleanup(self):
        """Cleanup resources."""
        if self.hardware_manager:
            self.hardware_manager.shutdown()
            self.hardware_manager = None
        logger.info("Worker cleanup complete")
    
    def stop(self):
        """Request stop."""
        self._stop_requested = True
        self.wait(5000)
    
    @property
    def is_running(self):
        return self._running


class MainWindow(QMainWindow):
    """Advanced main window with dockable panels."""
    
    def __init__(self, config=None):
        super().__init__()
        
        self.config = config
        self.worker: Optional[ProcessingWorker] = None
        
        self._setup_menubar()
        self._setup_toolbar()
        self._setup_ui()
        self._setup_docks()
        self._connect_signals()
        
        # Advanced features
        self.shortcuts = ShortcutManager(self)
        self.notifications = NotificationManager(self)
        
        logger.info("MainWindow initialized")
    
    def _setup_menubar(self):
        """Setup menu bar."""
        menubar = self.menuBar()
        menubar.setStyleSheet("""
            QMenuBar {
                background: rgba(0, 0, 0, 0.3);
                padding: 4px;
            }
            QMenuBar::item {
                padding: 4px 12px;
                border-radius: 4px;
            }
            QMenuBar::item:selected {
                background: rgba(100, 150, 255, 0.3);
            }
            QMenu {
                background: #2a2a4e;
                border: 1px solid rgba(255, 255, 255, 0.1);
            }
            QMenu::item {
                padding: 8px 24px;
            }
            QMenu::item:selected {
                background: rgba(100, 150, 255, 0.3);
            }
        """)
        
        # File menu
        file_menu = menubar.addMenu("&File")
        
        new_session = QAction("New Session", self)
        new_session.setShortcut(QKeySequence.StandardKey.New)
        file_menu.addAction(new_session)
        
        file_menu.addSeparator()
        
        export_action = QAction("Export Data...", self)
        export_action.setShortcut(QKeySequence("Ctrl+E"))
        file_menu.addAction(export_action)
        
        file_menu.addSeparator()
        
        exit_action = QAction("Exit", self)
        exit_action.setShortcut(QKeySequence.StandardKey.Quit)
        exit_action.triggered.connect(self.close)
        file_menu.addAction(exit_action)
        
        # View menu
        view_menu = menubar.addMenu("&View")
        self.view_menu = view_menu  # Store for dock toggles
        
        # Tools menu
        tools_menu = menubar.addMenu("&Tools")
        
        settings_action = QAction("Settings...", self)
        settings_action.setShortcut(QKeySequence("Ctrl+,"))
        settings_action.triggered.connect(self._open_settings)
        tools_menu.addAction(settings_action)
        
        tools_menu.addSeparator()
        
        calibrate_action = QAction("Calibration Wizard...", self)
        calibrate_action.triggered.connect(self._on_calibrate)
        tools_menu.addAction(calibrate_action)
        
        # Help menu
        help_menu = menubar.addMenu("&Help")
        
        about_action = QAction("About", self)
        about_action.triggered.connect(self._show_about)
        help_menu.addAction(about_action)
    
    def _setup_toolbar(self):
        """Setup toolbar."""
        toolbar = QToolBar("Main Toolbar")
        toolbar.setMovable(False)
        toolbar.setIconSize(QSize(24, 24))
        toolbar.setStyleSheet("""
            QToolBar {
                background: rgba(0, 0, 0, 0.2);
                border: none;
                padding: 4px;
                spacing: 4px;
            }
            QToolButton {
                padding: 8px;
                border-radius: 4px;
            }
            QToolButton:hover {
                background: rgba(100, 150, 255, 0.2);
            }
        """)
        self.addToolBar(toolbar)
        
        # Start/Stop
        self.start_action = QAction("â–¶ Start", self)
        self.start_action.triggered.connect(self._on_start)
        toolbar.addAction(self.start_action)
        
        self.stop_action = QAction("â¹ Stop", self)
        self.stop_action.setEnabled(False)
        self.stop_action.triggered.connect(self._on_stop)
        toolbar.addAction(self.stop_action)
        
        toolbar.addSeparator()
        
        # Recording
        self.record_action = QAction("âº Record", self)
        self.record_action.triggered.connect(self._toggle_recording)
        toolbar.addAction(self.record_action)
        
        toolbar.addSeparator()
        
        # Settings
        settings_action = QAction("âš™ Settings", self)
        settings_action.triggered.connect(self._open_settings)
        toolbar.addAction(settings_action)
    
    def _setup_ui(self):
        """Setup main UI with clean layout."""
        self.setWindowTitle("ðŸŽ™ï¸ Acoustic-Visual Fusion System")
        self.setMinimumSize(1400, 900)
        self.setStyleSheet(DARK_THEME)
        
        # Central widget
        central = QWidget()
        self.setCentralWidget(central)
        layout = QVBoxLayout(central)
        layout.setContentsMargins(4, 4, 4, 4)
        layout.setSpacing(4)
        
        # Main content tabs - clean styling from theme
        self.main_tabs = QTabWidget()
        self.main_tabs.setDocumentMode(True)  # Cleaner tabs
        
        # Camera view tab
        camera_widget = QWidget()
        camera_layout = QVBoxLayout(camera_widget)
        camera_layout.setContentsMargins(4, 4, 4, 4)
        self.camera_panel = CameraPanel()
        camera_layout.addWidget(self.camera_panel)
        self.main_tabs.addTab(camera_widget, "ðŸ“¹ Cameras")
        
        # 3D View tab
        self.scene_3d_panel = Scene3DPanel()
        self.main_tabs.addTab(self.scene_3d_panel, "ðŸŒ 3D Scene")
        
        # Analytics tab
        self.analytics_panel = AnalyticsPanel()
        self.main_tabs.addTab(self.analytics_panel, "ðŸ“Š Analytics")
        
        # Meeting Intelligence tab
        meeting_widget = QWidget()
        meeting_layout = QHBoxLayout(meeting_widget)
        meeting_layout.setContentsMargins(4, 4, 4, 4)
        
        self.meeting_panel = MeetingPanel()
        meeting_layout.addWidget(self.meeting_panel, 2)
        
        self.relationship_panel = RelationshipPanel()
        meeting_layout.addWidget(self.relationship_panel, 1)
        
        self.main_tabs.addTab(meeting_widget, "ðŸŽ™ï¸ Meeting")
        
        layout.addWidget(self.main_tabs, 1)
        
        # Timeline at bottom - compact
        self.timeline_panel = EventTimelinePanel()
        self.timeline_panel.setMaximumHeight(120)
        layout.addWidget(self.timeline_panel)
        
        # Status bar
        self.status_bar = QStatusBar()
        self.setStatusBar(self.status_bar)
        self._update_status("Ready - Click â–¶ Start to begin")
    
    def _setup_docks(self):
        """Setup dockable panels with optimized layout."""
        # Set dock widget styling
        dock_style = """
            QDockWidget {
                font-weight: 600;
            }
            QDockWidget::title {
                padding: 8px;
            }
        """
        
        # Controls dock (left) - Main control panel
        self.controls_dock = QDockWidget("âš™ï¸ Controls", self)
        self.controls_dock.setFeatures(
            QDockWidget.DockWidgetFeature.DockWidgetMovable |
            QDockWidget.DockWidgetFeature.DockWidgetFloatable
        )
        self.controls_dock.setStyleSheet(dock_style)
        self.controls_dock.setMinimumWidth(280)
        self.controls_dock.setMaximumWidth(350)
        self.controls_panel = ControlsPanel()
        self.controls_dock.setWidget(self.controls_panel)
        self.addDockWidget(Qt.DockWidgetArea.LeftDockWidgetArea, self.controls_dock)
        
        # Audio dock (right) - Primary right panel
        self.audio_dock = QDockWidget("ðŸŽ™ï¸ Audio", self)
        self.audio_dock.setFeatures(
            QDockWidget.DockWidgetFeature.DockWidgetMovable |
            QDockWidget.DockWidgetFeature.DockWidgetFloatable
        )
        self.audio_dock.setStyleSheet(dock_style)
        self.audio_dock.setMinimumWidth(300)
        self.audio_panel = AudioPanel()
        self.audio_dock.setWidget(self.audio_panel)
        self.addDockWidget(Qt.DockWidgetArea.RightDockWidgetArea, self.audio_dock)
        
        # Fusion dock (right, tabbed with audio)
        self.fusion_dock = QDockWidget("ðŸ”— Fusion", self)
        self.fusion_dock.setFeatures(
            QDockWidget.DockWidgetFeature.DockWidgetMovable |
            QDockWidget.DockWidgetFeature.DockWidgetFloatable
        )
        self.fusion_dock.setStyleSheet(dock_style)
        self.fusion_panel = FusionPanel()
        self.fusion_dock.setWidget(self.fusion_panel)
        self.addDockWidget(Qt.DockWidgetArea.RightDockWidgetArea, self.fusion_dock)
        
        # Recording dock (left, below controls)
        self.recording_dock = QDockWidget("ðŸŽ¬ Recording", self)
        self.recording_dock.setFeatures(
            QDockWidget.DockWidgetFeature.DockWidgetMovable |
            QDockWidget.DockWidgetFeature.DockWidgetFloatable
        )
        self.recording_dock.setStyleSheet(dock_style)
        self.recording_widget = RecordingWidget()
        self.recording_dock.setWidget(self.recording_widget)
        self.addDockWidget(Qt.DockWidgetArea.LeftDockWidgetArea, self.recording_dock)
        
        # Heatmap dock - Hidden by default, can be shown from View menu
        self.heatmap_dock = QDockWidget("ðŸ”¥ Heatmap", self)
        self.heatmap_dock.setFeatures(
            QDockWidget.DockWidgetFeature.DockWidgetMovable |
            QDockWidget.DockWidgetFeature.DockWidgetFloatable
        )
        self.heatmap_dock.setStyleSheet(dock_style)
        self.heatmap_panel = HeatmapPanel()
        self.heatmap_dock.setWidget(self.heatmap_panel)
        self.addDockWidget(Qt.DockWidgetArea.BottomDockWidgetArea, self.heatmap_dock)
        self.heatmap_dock.hide()  # Hidden by default
        
        # Alert dock - Hidden by default
        self.alert_dock = QDockWidget("ðŸ”” Alerts", self)
        self.alert_dock.setFeatures(
            QDockWidget.DockWidgetFeature.DockWidgetMovable |
            QDockWidget.DockWidgetFeature.DockWidgetFloatable
        )
        self.alert_dock.setStyleSheet(dock_style)
        self.alert_panel = AlertPanel()
        self.alert_dock.setWidget(self.alert_panel)
        self.addDockWidget(Qt.DockWidgetArea.RightDockWidgetArea, self.alert_dock)
        self.alert_dock.hide()  # Hidden by default
        
        # Stack right side docks as tabs
        self.tabifyDockWidget(self.audio_dock, self.fusion_dock)
        self.audio_dock.raise_()
        
        # Stack left side docks as tabs  
        self.tabifyDockWidget(self.controls_dock, self.recording_dock)
        self.controls_dock.raise_()
        
        # Add view menu toggles
        self.view_menu.addSeparator()
        self.view_menu.addAction(self.controls_dock.toggleViewAction())
        self.view_menu.addAction(self.audio_dock.toggleViewAction())
        self.view_menu.addAction(self.fusion_dock.toggleViewAction())
        self.view_menu.addAction(self.recording_dock.toggleViewAction())
        self.view_menu.addSeparator()
        self.view_menu.addAction(self.heatmap_dock.toggleViewAction())
        self.view_menu.addAction(self.alert_dock.toggleViewAction())
    
    def _connect_signals(self):
        """Connect signals and slots."""
        self.controls_panel.start_clicked.connect(self._on_start)
        self.controls_panel.stop_clicked.connect(self._on_stop)
        self.controls_panel.calibrate_clicked.connect(self._on_calibrate)
        self.controls_panel.settings_changed.connect(self._on_settings_changed)
    
    def _connect_worker_signals(self):
        """Connect worker signals."""
        if self.worker:
            self.worker.frame_ready.connect(self._on_frame_ready)
            self.worker.detections_ready.connect(self._on_detections_ready)
            self.worker.tracks_ready.connect(self._on_tracks_ready)
            self.worker.audio_ready.connect(self._on_audio_ready)
            self.worker.localization_ready.connect(self._on_localization_ready)
            self.worker.mic_levels_ready.connect(self._on_mic_levels_ready)
            self.worker.fusion_ready.connect(self._on_fusion_ready)
            self.worker.stats_ready.connect(self._on_stats_ready)
            self.worker.devices_ready.connect(self._on_devices_ready)
            self.worker.event_detected.connect(self._on_event_detected)
            self.worker.meeting_data_ready.connect(self._on_meeting_data_ready)
            self.worker.error_signal.connect(self._on_error)
    
    def _update_status(self, message: str):
        self.status_bar.showMessage(f"  {message}")
    
    def _on_start(self):
        """Start processing."""
        try:
            from ..core.config import get_config
            
            self._update_status("Initializing system...")
            
            config = self.config or get_config()
            self.worker = ProcessingWorker(config)
            self._connect_worker_signals()
            
            self.worker.start()
            
            self.controls_panel.set_running(True)
            self.start_action.setEnabled(False)
            self.stop_action.setEnabled(True)
            self._update_status("System starting...")
            
        except Exception as e:
            logger.error(f"Failed to start: {e}")
            QMessageBox.critical(self, "Error", f"Failed to start: {e}")
    
    def _on_stop(self):
        """Stop processing."""
        try:
            self._update_status("Stopping...")
            
            if self.worker:
                self.worker.stop()
                self.worker = None
            
            self.controls_panel.set_running(False)
            self.start_action.setEnabled(True)
            self.stop_action.setEnabled(False)
            self._update_status("System stopped")
            
        except Exception as e:
            logger.error(f"Failed to stop: {e}")
    
    def _toggle_recording(self):
        """Toggle recording."""
        if self.recording_widget.is_recording:
            self.recording_widget._stop_recording()
            self.record_action.setText("âº Record")
        else:
            self.recording_widget._start_recording()
            self.record_action.setText("âº Recording...")
    
    def _on_calibrate(self):
        QMessageBox.information(self, "Calibration", 
            "Calibration wizard coming soon.")
    
    def _open_settings(self):
        dialog = SettingsDialog(self.config, self)
        if dialog.exec():
            logger.info(f"Settings updated: {dialog.changes}")
    
    def _show_about(self):
        QMessageBox.about(self, "About",
            "ðŸŽ™ï¸ Acoustic-Visual Fusion System\n\n"
            "Version 1.0.0\n\n"
            "Real-time 3D sound source localization with\n"
            "visual tracking and audio-visual correlation.")
    
    def _on_settings_changed(self, settings: dict):
        logger.debug(f"Settings changed: {settings}")
    
    def _on_devices_ready(self, cameras: list, microphones: list):
        logger.info(f"Devices ready: {len(cameras)} cameras, {len(microphones)} mics")
        self.camera_panel.setup_cameras(cameras)
        self.audio_panel.setup_microphones(microphones)
        
        # Setup 3D scene with mic positions
        mic_positions = [(i * 0.3, 0, 0.1) for i in range(len(microphones))]
        self.scene_3d_panel.scene.set_microphones(mic_positions)
        
        cam_positions = [(0, -2, 1.5), (2, 0, 1.5), (0, 2, 1.5)][:len(cameras)]
        self.scene_3d_panel.scene.set_cameras(cam_positions)
        
        self._update_status(f"Running: {len(cameras)} cameras, {len(microphones)} mics")
    
    def _on_frame_ready(self, camera_id: str, frame: np.ndarray, fps: float):
        self.camera_panel.update_camera(camera_id, frame, fps)
        self.analytics_panel.increment_frame()
        
        # Recording
        if self.recording_widget.is_recording:
            self.recording_widget.add_frame(camera_id, frame)
    
    def _on_detections_ready(self, camera_id: str, detections: list):
        self.camera_panel.set_camera_detections(camera_id, detections)
    
    def _on_tracks_ready(self, tracks: list):
        for track in tracks:
            cam_id = track.get('camera', '')
            if cam_id:
                self.camera_panel.set_camera_tracks(cam_id, [track])
            
            # Update heatmap with track
            self.heatmap_panel.add_track(track)
        
        # Update 3D scene
        persons = [(0, i * 0.5, 1.7, 1.7, track['id'], track.get('is_speaking', False))
                   for i, track in enumerate(tracks)]
        self.scene_3d_panel.scene.set_persons(persons)
        
        track_positions = [(0, 0, track['id'], track.get('is_speaking', False))
                          for track in tracks]
        self.fusion_panel.update_spatial_map([], track_positions)
    
    def _on_audio_ready(self, samples: np.ndarray):
        self.audio_panel.update_waveform(samples)
    
    def _on_localization_ready(self, position, confidence):
        self.audio_panel.update_localization(position, confidence, 0, "")
        
        # Update heatmap with sound source
        self.heatmap_panel.add_sound_source(position, confidence)
        
        sources = [(position[0], position[1], confidence)]
        self.fusion_panel.update_spatial_map(sources, [])
        self.scene_3d_panel.scene.set_sound_sources(
            [(position[0], position[1], position[2], confidence, "Sound")]
        )
    
    def _on_mic_levels_ready(self, levels: dict):
        for mic_id, (level, db) in levels.items():
            self.audio_panel.update_mic_level(mic_id, level, db)
    
    def _on_fusion_ready(self, sources: list, tracks: list, correlations: list):
        self.fusion_panel.update_spatial_map(sources, tracks)
        self.fusion_panel.update_correlations(correlations)
    
    def _on_stats_ready(self, fps: float, latency: float, cpu: float, gpu: float):
        self.controls_panel.update_stats(fps, latency, cpu, gpu)
        self.analytics_panel.update_performance(fps, latency, cpu, gpu)
    
    def _on_event_detected(self, event_type: str, label: str, confidence: float):
        """Handle detected events."""
        try:
            etype = EventType(event_type) if event_type in [e.value for e in EventType] \
                    else EventType.ACTIVITY
        except:
            etype = EventType.ACTIVITY
        
        self.timeline_panel.add_event(etype, label, 0.5, confidence)
        self.analytics_panel.increment_event()
    
    def _on_error(self, error: str):
        QMessageBox.warning(self, "Processing Error", error)
    
    def _on_meeting_data_ready(self, data: dict):
        """Handle meeting analytics data update."""
        try:
            # Update meeting panel with real data
            self.meeting_panel.update_data(data)
            
            # Update relationship graph
            for pid, pdata in data.get("participants", {}).items():
                self.relationship_panel.add_participant(pid, pdata.get("name", pid))
                self.relationship_panel.update_participant(
                    pid, 
                    is_speaking=pdata.get("is_speaking", False),
                    talk_time=pdata.get("talk_time", 0)
                )
        except Exception as e:
            logger.debug(f"Meeting data update error: {e}")
    
    def closeEvent(self, event):
        if self.worker and self.worker.is_running:
            reply = QMessageBox.question(
                self, "Confirm Exit",
                "System is running. Stop and exit?",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
            )
            
            if reply == QMessageBox.StandardButton.No:
                event.ignore()
                return
            
            self._on_stop()
        
        event.accept()


def run_gui(config=None):
    """Run the PyQt6 GUI application."""
    app = QApplication(sys.argv)
    
    app.setApplicationName("AV-Fusion")
    app.setApplicationVersion("1.0.0")
    app.setOrganizationName("AcousticVisual")
    
    font = QFont("Segoe UI", 10)
    app.setFont(font)
    
    window = MainWindow(config)
    window.show()
    
    sys.exit(app.exec())


if __name__ == "__main__":
    run_gui()
